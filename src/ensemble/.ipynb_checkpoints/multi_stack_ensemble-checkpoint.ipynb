{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Stack Ensemble\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser\n",
    "---\n",
    "Parse the submissions setting the value assigned to each item to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(sc, path):\n",
    "    # Create rdd\n",
    "    rdd = sc.textFile(path)\n",
    "    # Select header to be removed\n",
    "    header = rdd.first()\n",
    "\n",
    "    rdd = (rdd.filter(lambda x: x != header)\n",
    "           .map(lambda x: x.split(\"\\t\"))\n",
    "           .filter(lambda x: x[0] != '')\n",
    "           .map(lambda x:(int(x[0]),setup_items(x[1])))\n",
    "    )\n",
    "\n",
    "    return rdd\n",
    "\n",
    "def setup_items(items):\n",
    "    item_rank = 0\n",
    "    items_list = []\n",
    "    items_split = items.split(',')\n",
    "    \n",
    "    for item in items_split:\n",
    "        if item != '':\n",
    "            items_list.append((int(item),++item_rank,0))\n",
    "            \n",
    "    return items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interaction_rdd = parse(sc, \"./submissions/\")\n",
    "impression_rdd = parse(sc, \"./submissions/\")\n",
    "\n",
    "cf_intint_rdd = parse(sc, \"./submissions/\")\n",
    "cf_intimp_rdd = parse(sc, \"./submissions/\")\n",
    "cf_impint_rdd = parse(sc, \"./submissions/\")\n",
    "cf_impimp_rdd = parse(sc, \"./submissions/\")\n",
    "cf_i_intint_rdd = parse(sc, \"./submissions/\")\n",
    "cf_i_impimp_rdd = parse(sc, \"./submissions/\")\n",
    "\n",
    "cb_idf_rdd = parse(sc, \"./submissions/\")\n",
    "cb_concept_rdd = parse(sc, \"./submissions/\")\n",
    "\n",
    "baseline_rdd = parse(sc, \"./submissions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rdd = parse(sc, \"/Users/tommy/Documents/pumpkin-pie/top_pop.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scorer\n",
    "===\n",
    "Assigns to each item a value based on the chosen algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_scorer(sc, rdd, score, decay):\n",
    "    \"\"\"Assign a value using a linear algorithm.\n",
    "    score is the value given to that learner.\"\"\"\n",
    "    \n",
    "    scored_rdd = rdd.map(lambda x: (x[0], linear_calculator(x[1], score, decay)))\n",
    "    return scored_rdd\n",
    "    \n",
    "def linear_calculator(tuples, score, decay):\n",
    "    scored_tuples = []\n",
    "    \n",
    "    for t in tuples:\n",
    "        scored_tuples.append((t[0], t[1], score - t[1]*decay))\n",
    "    \n",
    "    return scored_tuples\n",
    "\n",
    "def evaluation_scorer(sc, rdd, score):\n",
    "    \"\"\"Assign a value based on the score obtained on the online leaderboard and the evaluation metric.\"\"\"\n",
    "    \n",
    "    number_of_items = calculate_number_of_items(sc, rdd)\n",
    "    scored_rdd = rdd.map(lambda x: (x[0], evaluation_calculator(x[1], score, number_of_items)))\n",
    "    \n",
    "    return scored_rdd\n",
    "\n",
    "def calculate_number_of_items(sc, rdd):\n",
    "    return sum(rdd.filter(lambda x: x != header)\n",
    "                .map(lambda x: x.split(\"\\t\"))\n",
    "                .filter(lambda x: x[0] != '')\n",
    "                .map(lambda x: len(get_items(x[1]))).collect())\n",
    "    \n",
    "def evaluation_calculator(tuples, score, number_of_items):\n",
    "    scored_tuples = []\n",
    "    \n",
    "    for t in tuples:\n",
    "        scored_tuples.append((t[0], t[1], score * 1000 / number_of_items))\n",
    "        \n",
    "    return scored_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble(sc, rdd_list):\n",
    "    ensemble_rdd = sc.emptyRDD()\n",
    "    \n",
    "    for rdd in rdd_list:\n",
    "        ensemble_rdd.union(rdd)\n",
    "        \n",
    "    return ensemble_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def create_linear_combination(values_pool, decays_pool, number_of_elements):\n",
    "    combination = []\n",
    "    \n",
    "    for v in range(0,len(values_pool)):\n",
    "        for d in range(0, len(decays_pool)):\n",
    "            combination.append((values_pool[v], decays_pool[d]))\n",
    "        \n",
    "    return itertools.combinations(combination, number_of_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Ensembler - Level 1\n",
    "===\n",
    "Collaborative Filtering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = ensemble(sc, [\n",
    "            linear_scorer(sc, test_rdd, 2, 0.001)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  LINEAR\n",
    "#\n",
    "\n",
    "searched_list = []\n",
    "\n",
    "values_pool = [0,1,2]\n",
    "decays_pool = [0.001,0.0015,0.002]\n",
    "\n",
    "# The third parameters is the number of submissions that we have in this level of the stack\n",
    "combinations = create_linear_combination(values_pool, decays_pool, 6)\n",
    "\n",
    "for combination in combinations:\n",
    "    lin_stack_1_1 = ensemble(sc, [\n",
    "            linear_scorer(sc, cf_intint_rdd, combination[0][0], combination[0][1]),\n",
    "            linear_scorer(sc, cf_intimp_rdd, combination[1][0], combination[1][1]),\n",
    "            linear_scorer(sc, cf_impint_rdd, combination[2][0], combination[2][1]),\n",
    "            linear_scorer(sc, cf_impimp_rdd, combination[3][0], combination[3][1]),\n",
    "            linear_scorer(sc, cf_i_intint_rdd, combination[4][0], combination[4][1]),\n",
    "            linear_scorer(sc, cf_i_impimp_rdd, combination[5][0], combination[5][1])\n",
    "        ])\n",
    "    \n",
    "    # Evaluate the ensemble\n",
    "    lin_score = \n",
    "    searched_list.append((lin_score, combination, lin_stack_1_1))\n",
    "\n",
    "for s in sorted(searched_list, key=itemgetter(x[0]), reverse=True):\n",
    "    print str(s) + \" ;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  EVALUATION SCORE\n",
    "#\n",
    "\n",
    "eval_stack_1_1 = ensemble(sc, [\n",
    "            evaluation_scorer(cf_intint_rdd, ),\n",
    "            evaluation_scorer(cf_intimp_rdd, ),\n",
    "            evaluation_scorer(cf_impint_rdd, ),\n",
    "            evaluation_scorer(cf_impimp_rdd, ),\n",
    "            evaluation_scorer(cf_i_intint_rdd, ),\n",
    "            evaluation_scorer(cf_i_impimp_rdd, )\n",
    "        ])\n",
    "    \n",
    "# Evaluate the ensemble\n",
    "eval_score = \n",
    "print \"Evaluation score stack lv 1.1: \" + str(eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_stack_1_1 = sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][2] \\\n",
    "                if max(sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][0], eval_score) != eval_score \\\n",
    "                else eval_stack_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content-Based\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  LINEAR\n",
    "#\n",
    "\n",
    "searched_list = []\n",
    "\n",
    "values_pool = [0,1]\n",
    "decays_pool = [0.001,0.0015,0.002]\n",
    "\n",
    "# The third parameters is the number of submissions that we have in this level of the stack\n",
    "combinations = create_linear_combination(values_pool, decays_pool, 2)\n",
    "\n",
    "for combination in combinations:\n",
    "    lin_stack_1_2 = ensemble(sc, [\n",
    "            linear_scorer(sc, cb_idf_rdd, combination[0][0], combination[0][1]),\n",
    "            linear_scorer(sc, cb_concept_rdd, combination[1][0], combination[1][1])\n",
    "        ])\n",
    "    \n",
    "    # Evaluate the ensemble\n",
    "    lin_score = \n",
    "    searched_list.append((lin_score, combination, lin_stack_1_2))\n",
    "    \n",
    "for s in sorted(searched_list, key=itemgetter(x[0]), reverse=True):\n",
    "    print str(s) + \" ;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  EVALUATION SCORE\n",
    "#\n",
    "\n",
    "eval_stack_1_2 = ensemble(sc, [\n",
    "            evaluation_scorer(cb_idf_rdd, ),\n",
    "            evaluation_scorer(cb_concept_rdd, )\n",
    "        ])\n",
    "    \n",
    "# Evaluate the ensemble\n",
    "eval_score = \n",
    "print \"Evaluation score stack lv 1.2: \" + str(eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_stack_1_2 = sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][2] \\\n",
    "                if max(sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][0], eval_score) != eval_score \\\n",
    "                else eval_stack_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Stack Ensembler - Level 2\n",
    "===\n",
    "Collaborative + Content\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  LINEAR\n",
    "#\n",
    "\n",
    "searched_list = []\n",
    "\n",
    "values_pool = [0,1]\n",
    "decays_pool = [0.001,0.0015,0.002]\n",
    "\n",
    "# The third parameters is the number of submissions that we have in this level of the stack\n",
    "combinations = create_linear_combination(values_pool, decays_pool, 2)\n",
    "\n",
    "for combination in combinations:\n",
    "    lin_stack_2 = ensemble(sc, [\n",
    "            linear_scorer(sc, best_stack_1_1, combination[0][0], combination[0][1]),\n",
    "            linear_scorer(sc, best_stack_1_2, combination[1][0], combination[1][1])\n",
    "        ])\n",
    "    \n",
    "    # Evaluate the ensemble\n",
    "    lin_score = \n",
    "    searched_list.append((lin_score, combination, lin_stack_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  EVALUATION SCORE\n",
    "#\n",
    "\n",
    "stack_2 = ensemble(sc, [\n",
    "            evaluation_scorer(best_stack_1_1, ),\n",
    "            evaluation_scorer(best_stack_1_2, )\n",
    "        ])\n",
    "    \n",
    "# Evaluate the ensemble\n",
    "score = \n",
    "print \"Evaluation score stack lv 2: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_stack_2 = sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][2] \\\n",
    "                if max(sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][0], eval_score) != eval_score \\\n",
    "                else eval_stack_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Ensembler - Level 3\n",
    "===\n",
    "Int + Imp + Level_2 + Baseline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  LINEAR\n",
    "#\n",
    "\n",
    "searched_list = []\n",
    "\n",
    "values_pool = [0,1,2]\n",
    "decays_pool = [0.001,0.0015,0.002]\n",
    "\n",
    "# The third parameters is the number of submissions that we have in this level of the stack\n",
    "combinations = create_linear_combination(values_pool, decays_pool, 4)\n",
    "\n",
    "for combination in combinations:\n",
    "    lin_stack_3 = ensemble(sc, [\n",
    "            linear_scorer(sc, interactions_rdd, combination[0][0], combination[0][1]),\n",
    "            linear_scorer(sc, impressions_rdd, combination[1][0], combination[1][1])\n",
    "            linear_scorer(sc, best_stack_2, combination[2][0], combination[2][1])\n",
    "            linear_scorer(sc, baseline_rdd, combination[3][0], combination[3][1])\n",
    "        ])\n",
    "    \n",
    "    # Evaluate the ensemble\n",
    "    lin_score = \n",
    "    searched_list.append((lin_score, combination, lin_stack_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  EVALUATION SCORE\n",
    "#\n",
    "\n",
    "stack_3 = ensemble(sc, [\n",
    "            evaluation_scorer(interactions_rdd, ),\n",
    "            evaluation_scorer(impressions_rdd, ),\n",
    "            evaluation_scorer(best_stack_2, ),\n",
    "            evaluation_scorer(baseline_rdd, )\n",
    "        ])\n",
    "    \n",
    "# Evaluate the ensemble\n",
    "score = \n",
    "print \"Evaluation score stack lv 3: \" + str(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_stack_3 = sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][2] \\\n",
    "                if max(sorted(searched_list, key=itemgetter(x[0]), reverse=True)[0][0], eval_score) != eval_score \\\n",
    "                else eval_stack_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Recommendation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
