{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imp\n",
    "mt = imp.load_source('metrics', '../evaluation_metric/metrics.py')\n",
    "from utils import merge_utils as mu\n",
    "from utils import write_utils as wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(sc, path):\n",
    "    # Create rdd\n",
    "    rdd = sc.textFile(path)\n",
    "    # Select header to be removed\n",
    "    header = rdd.first()\n",
    "\n",
    "    rdd = (rdd.filter(lambda x: x != header)\n",
    "           .map(lambda x: x.split(\"\\t\"))\n",
    "           .filter(lambda x: x[0] != '')\n",
    "           .map(lambda x:(int(x[0]),setup_items(x[1])))\n",
    "    )\n",
    "\n",
    "    return rdd\n",
    "\n",
    "def setup_items(items):\n",
    "    item_rank = 0\n",
    "    items_list = []\n",
    "    items_split = items.split(',')\n",
    "    \n",
    "    for item in items_split:\n",
    "        if item != '':\n",
    "            item_rank += 1\n",
    "            items_list.append((int(item),item_rank,0))\n",
    "            \n",
    "    return items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#interaction_rdd = parse(sc, \"./submissions/\")\n",
    "#impression_rdd = parse(sc, \"./submissions/\")\n",
    "\n",
    "cf_intint_rdd = parse(sc, \"../../Submissions/ens_subs/cf_int_int_18.9k.csv\")\n",
    "cf_intimp_rdd = parse(sc, \"../../Submissions/ens_subs/cf_int_imp_22.4k.csv\")\n",
    "cf_impint_rdd = parse(sc, \"../../Submissions/ens_subs/imp_imp_int_int_33.2k_avg.csv\")\n",
    "cf_impimp_rdd = parse(sc, \"../../Submissions/ens_subs/cf_imp_imp_31k.csv\")\n",
    "cf_i_intint_rdd = parse(sc, \"../../Submissions/ens_subs/true_10k_CF_ITEM_greater_3_shr=1_knn=750_22k.csv\")\n",
    "cf_i_impimp_rdd = parse(sc, \"../../Submissions/ens_subs/cf_item_imp_imp_20k.csv\")\n",
    "\n",
    "cb_idf_rdd = parse(sc, \"../../Submissions/ens_subs/idf_45k.csv\")\n",
    "cb_concept_rdd = parse(sc, \"../../Submissions/ens_subs/tf_ervin_37k.csv\")\n",
    "\n",
    "#baseline_rdd = parse(sc, \"./submissions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.83\n"
     ]
    }
   ],
   "source": [
    "def parse(sc, path):\n",
    "    rdd = sc.textFile(path)\n",
    "    header = rdd.first()\n",
    "    rdd = (rdd.filter(lambda x: x != header)\n",
    "           .map(lambda x: x.split(\"\\t\"))\n",
    "           .map(lambda x: (int(x[0]),float(x[1]))))\n",
    "    return rdd.collect()\n",
    "\n",
    "scorer_dict = dict(parse(sc, \"/Users/tommy/Downloads/pesi.csv\"))\n",
    "print scorer_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_scorer(sc, rdd, score, decay):\n",
    "    \"\"\"Assign a value using a linear algorithm.\n",
    "    score is the value given to that learner.\"\"\"\n",
    "    \n",
    "    scored_rdd = rdd.map(lambda x: (x[0], linear_calculator(x[1], score, decay)))\n",
    "    return scored_rdd\n",
    "    \n",
    "def linear_calculator(tuples, score, decay):\n",
    "    scored_tuples = []\n",
    "    \n",
    "    for t in tuples:\n",
    "        scored_tuples.append((t[0], t[1], score - t[1]*decay))\n",
    "    \n",
    "    return scored_tuples\n",
    "\n",
    "def evaluate_score(rank, score):\n",
    "    print rank\n",
    "    return 1.*score*scorer_dict[int(rank)]\n",
    "\n",
    "def get_value_at_k(items, score):\n",
    "    scored_items = []\n",
    "    print items\n",
    "    for i in range(0,len(items)-1):\n",
    "        scored_items.append((int(items[i][0]), items[i][1], evaluate_score(items[i][1], score)))\n",
    "    \n",
    "    return scored_items\n",
    "\n",
    "def evaluation_scorer(sc, rdd, score):\n",
    "    \"\"\"Assign a value based on the score obtained on the online leaderboard and the evaluation metric.\"\"\"\n",
    "    n_items = calculate_number_of_items(sc, rdd)\n",
    "    scored_rdd = rdd.map(lambda x:(x[0], get_value_at_k(x[1][:30], (1. * score * 10**3)/n_items)))\n",
    "    \n",
    "    return scored_rdd\n",
    "\n",
    "def calculate_number_of_items(sc, rdd):\n",
    "    return sum(rdd.map(lambda x: len(x[1])).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble(sc, rdd_list):\n",
    "    combination_rdd = sc.emptyRDD()\n",
    "    \n",
    "    for rdd in rdd_list:\n",
    "        combination_rdd = combination_rdd.union(rdd.map(lambda x: (x[0], [(i[0],i[2]) for i in x[1]])))\n",
    "        \n",
    "    ensemble_rdd = (combination_rdd.flatMap(lambda r: [(r[0], x) for x in r[1]])\n",
    "                 .map(lambda x: ((x[0],x[1][0]),x[1][1]))\n",
    "                 .reduceByKey(lambda x,y:x+y)\n",
    "                 .map(lambda x: (x[0][0],[(x[0][1],x[1])]))\n",
    "                 .reduceByKey(lambda x,y:x+y)\n",
    "                 .map(lambda x: (x[0],sorted(x[1], key=itemgetter(1), reverse=True)[:30]))\n",
    "                 )\n",
    "        \n",
    "    return ensemble_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "#  LINEAR\n",
    "#\n",
    "\n",
    "lin_stack_1_1 = ensemble(sc, [\n",
    "            linear_scorer(sc, cf_intint_rdd, 1, 0.0001),\n",
    "            linear_scorer(sc, cf_intimp_rdd, 1, 0.0001),\n",
    "            linear_scorer(sc, cf_impint_rdd, 1, 0.0001),\n",
    "            linear_scorer(sc, cf_impimp_rdd, 1, 0.0001),\n",
    "            linear_scorer(sc, cf_i_intint_rdd, 1, 0.0001),\n",
    "            linear_scorer(sc, cf_i_impimp_rdd, 1, 0.0001)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file results/linear1.1_1.1_1.1_1.1_1.1_1.1_1.1 created successfully\n"
     ]
    }
   ],
   "source": [
    "wu.prepareSubmission(lin_stack_1_1,\"results/linear1.1_1.1_1.1_1.1_1.1_1.1_1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_stack_1_1 = ensemble(sc, [\n",
    "            evaluation_scorer(sc, cf_intint_rdd, 18.9),\n",
    "            evaluation_scorer(sc, cf_intimp_rdd, 22.4),\n",
    "            evaluation_scorer(sc, cf_impint_rdd, 33.2),\n",
    "            evaluation_scorer(sc, cf_impimp_rdd, 31),\n",
    "            evaluation_scorer(sc, cf_i_intint_rdd, 22),\n",
    "            evaluation_scorer(sc, cf_i_impimp_rdd, 20)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file results/eval1.1 created successfully\n"
     ]
    }
   ],
   "source": [
    "wu.prepareSubmission(eval_stack_1_1,\"results/eval1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_stack_1_2 = ensemble(sc, [\n",
    "            linear_scorer(sc, cb_idf_rdd, 1, 0.0001),\n",
    "            linear_scorer(sc, cb_concept_rdd, 1, 0.00025)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file results/linear1.2__1.1_1.25 created successfully\n"
     ]
    }
   ],
   "source": [
    "wu.prepareSubmission(lin_stack_1_2,\"results/linear1.2__1.1_1.25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_stack_1_2 = ensemble(sc, [\n",
    "            evaluation_scorer(sc, cb_idf_rdd, 45),\n",
    "            evaluation_scorer(sc, cb_concept_rdd, 37)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file results/eval1.2 created successfully\n"
     ]
    }
   ],
   "source": [
    "wu.prepareSubmission(eval_stack_1_2,\"results/eval1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
