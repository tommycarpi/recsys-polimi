{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import merge_utils as mu\n",
    "import write_utils as wu\n",
    "import parse_utils as pu\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommendation_list(string):\n",
    "    lista=[]\n",
    "    split = string.split(',')\n",
    "    for i in split:\n",
    "        if i != '':\n",
    "            lista.append((int(i)))\n",
    "            \n",
    "    return lista\n",
    "\n",
    "def parse_submission(sc, path):\n",
    "    rdd = sc.textFile(path)\n",
    "    \n",
    "    header = rdd.first()\n",
    "\n",
    "    rdd = (rdd.filter(lambda x: x != header)\n",
    "    .map(lambda x: x.split(\"\\t\"))\n",
    "    .filter(lambda x: x[0] != '')\n",
    "    .map(lambda x:(int(x[0]),recommendation_list(x[1])))\n",
    "    )\n",
    "\n",
    "    return rdd\n",
    "\n",
    "def recommendation_list_with_value(string, value):\n",
    "    updating_value = value\n",
    "    lista=[]\n",
    "    split = string.split(',')\n",
    "    for i in split:\n",
    "        if i != '':\n",
    "            updating_value -= 0.0001\n",
    "            lista.append((int(i),updating_value))\n",
    "            \n",
    "    return lista\n",
    "\n",
    "def psv(sc, path, value):\n",
    "    rdd = sc.textFile(path)\n",
    "    \n",
    "    header = rdd.first()\n",
    "\n",
    "    rdd = (rdd.filter(lambda x: x != header)\n",
    "    .map(lambda x: x.split(\"\\t\"))\n",
    "    .filter(lambda x: x[0] != '')\n",
    "    .map(lambda x:(int(x[0]),recommendation_list_with_value(x[1], value)))\n",
    "    )\n",
    "\n",
    "    return rdd\n",
    "\n",
    "def rdd_no_header(rdd):\n",
    "    header = rdd.first()\n",
    "    return rdd.filter(lambda x: x!=header)\n",
    "\n",
    "def get_sim_dict(sim_rdd):\n",
    "    return (rdd_no_header(sim_rdd)\n",
    "                .map(lambda x:x.split(\"\\t\"))\n",
    "                .filter(lambda x:x[0]!='' or x[1]!='')\n",
    "                .map(lambda x:(int(x[0]),from_string_to_list(x[1], 30)))\n",
    "               )\n",
    "\n",
    "def get_weight_value(jobs, value):\n",
    "    if len(jobs) > 0:\n",
    "        return [(i[0],i[1]) for i in jobs[:50]]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def psvs(sc, path, value):\n",
    "    rdd = sc.textFile(path)\n",
    "    rec_rdd = (get_sim_dict(rdd)\n",
    "               .map(lambda x: (x[0], get_weight_value(x[1], value)))\n",
    "               .filter(lambda x: len(x[1]) > 0))\n",
    "    \n",
    "    return rec_rdd\n",
    "\n",
    "def from_string_to_list(stringa,kNN=30):\n",
    "    lista_stringa = stringa.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"(\",\"\").split(\"),\")\n",
    "    lista_stringa = [i.replace(\")\",\"\").split(\", \") for i in lista_stringa]\n",
    "    final=[]\n",
    "    for tup in lista_stringa:\n",
    "        if tup[0]!='':# or tup[1]!='':\n",
    "            final.append((int(tup[0]),float(tup[1])))\n",
    "    \n",
    "    return sorted(final,key=itemgetter(1),reverse=True)[:kNN]\n",
    "\n",
    "def filter_data(x):\n",
    "    user = x[0]\n",
    "    jobs = x[1]\n",
    "    \n",
    "    to_be_filter = union_dict.get(user)\n",
    "    if to_be_filter != None:\n",
    "        return [j for j in jobs if int(j[0]) not in to_be_filter]\n",
    "    else:\n",
    "        return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2818048, [161771])]\n",
      "[(621311, [1037920, 2382594, 1515140, 2501, 2606598, 2163175, 143112, 653321, 1578157, 1710350, 1587453, 968753, 2190578, 2270308, 239162, 1661883, 2844858, 306686, 1222303])]\n",
      "[(2506752, [90120, 1053452, 950420, 1423129, 1754395, 996894, 820002, 693415, 2486575, 1171976, 938290, 164276, 348599, 1755963, 854206, 2773055, 2715712, 1827778, 811077, 581327, 2834514, 926933, 934872, 521945, 1356639, 784737, 2117988, 1108837, 1982203, 166784, 1754884, 1171976, 1842710, 1423129, 1078303, 693415, 938290, 2138292, 2547004, 1232957, 1487551, 1827778, 78669, 581327, 2834514, 2080350, 1356639, 2117988, 1108837, 2773055, 2287467, 838894, 1054322, 2383094, 1004665, 1982203, 1366336, 213441, 1244196, 1190437, 2235910, 2071368, 277062, 715276, 572690, 270559, 2486575, 2834514, 959545, 1092821, 1058425, 1194436, 1920047, 1206685, 1666847, 2146624, 648769, 79531, 619366, 277062, 1954727, 2071368, 2235910, 2799947, 78669, 1636910, 2486575, 953872, 2350577, 2834514, 926933, 348599, 404535, 2761896, 2715712, 820002, 875907, 811077, 619366, 693415, 90120, 404535, 534059, 1053452, 938290, 1149646, 2486575, 2834514, 926933, 348599, 2448923, 2176889, 1487551, 1232957, 2097631, 90120, 1053452, 996894, 1422500, 693415, 2486575, 938290, 404535, 1232957, 1487551, 2715712, 811077, 348599, 581327, 2834514, 926933, 521945, 2097631, 2117988, 1108837, 619366, 1809132, 2323313, 2773055, 397952, 1754884, 1171976, 950420, 849175, 1423129, 693415, 475053, 2381614, 938290, 2138292, 1232957, 1827778, 811077, 2194630, 2038489, 345950, 347104, 2117988, 1108837, 1450092, 1054322, 2383094, 1013112, 1263871, 2834514, 1487551])]\n"
     ]
    }
   ],
   "source": [
    "interactions_rdd = (pu.parseInteractions(sc, \"../../Dataset/interactions.csv\")\n",
    "                  .map(lambda x: (x.userId, [x.itemId])).reduceByKey(lambda x,y: x+y)\n",
    "                  .map(lambda x: (x[0], list(set(x[1])))))\n",
    "print interactions_rdd.take(1)\n",
    "\n",
    "impressions_rdd = (pu.parseImpressions(sc, \"/Users/tommy/Downloads/impressions.csv\")\n",
    "                  .map(lambda x: (x.userId, x.itemIds))\n",
    "                  .map(lambda x: (x[0], list(set(x[1])))))\n",
    "print impressions_rdd.take(1)\n",
    "\n",
    "union_rdd = impressions_rdd.union(interactions_rdd).reduceByKey(lambda x,y: x+y)\n",
    "print union_rdd.take(1)\n",
    "\n",
    "union_dict = dict(union_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#submission_name = \"../../Submissions/ens_subs/tf_ervin_95k.csv\"\n",
    "submission_name = \"/Users/tommy/Downloads/TFIDFMarco_noint.csv\"\n",
    "submission_rdd = psv(sc, submission_name, 1).map(lambda x: (x[0], x[1][:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommendation_rdd = submission_rdd.map(lambda x: (x[0], filter_data(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file ../../Submissions/ens_subs/new_idf created successfully\n"
     ]
    }
   ],
   "source": [
    "wu.prepareSubmission(recommendation_rdd, \"../../Submissions/ens_subs/new_idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
